{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb30a1e-e400-4751-b927-bd088ee35b15",
   "metadata": {},
   "source": [
    "## 3.4. Metrics and scoring: quantifying the quality of predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c7e8c",
   "metadata": {},
   "source": [
    "### 3.4.1. Choose score function?\n",
    "- Which scoring function should I use?\n",
    "- Which scoring function is a good one for my task?\n",
    "\n",
    "It is useful to distinguish two steps:\n",
    "- Predicting\n",
    "- Decision making\n",
    "\n",
    "**Predicting**: Usually, the response variable is a random variable, in the sense that there is no deterministic function of the features. $Y=g(X)$ , we usually choose a stat. property as the result. Such as mean,median,quantile \n",
    "\n",
    "It is best used for both: \n",
    "- as loss function for model training \n",
    "- as metric/score in model evaluation and model comparison.\n",
    "\n",
    "**Decision Making**:The result is a single outcome,There are many scoring functions which measure different aspects of such a decision, most of them are covered with or derived from the `metrics.confusion_matrix`.\n",
    "\n",
    "|functional         | scoring or loss function                          |  response `y`       |   prediction|\n",
    "|-------------------|---------------------------------------------------|---------------------|-------------|\n",
    "|**Classification**||||\n",
    "|mode               | zero-one loss        |multi-class           |``predict``, categorical|\n",
    "**Regression**\n",
    "|mean                |mean_squared_error|  all reals             |``predict``, all reals|\n",
    "|median              |mean_absolute_error |         all reals      |       ``predict``, all reals|\n",
    "|quantile           |pinball_loss     |           all reals         |    ``predict``, all reals|\n",
    "\n",
    "1. $R^2$ gives the same ranking as squared error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604a58f",
   "metadata": {},
   "source": [
    "### 3.4.2. Scoring API overview\n",
    "There are 3 different APIs for evaluating the quality of a model’s predictions:  \n",
    "1. Estimator score method: Estimators(model) have a score method providing a default evaluation criterion.\n",
    "- classifiers ：  accuracy \n",
    "- regressors：$R^2$\n",
    "2. Scoring parameter: Model-evaluation tools that use cross-validation (such as model_selection.GridSearchCV..) rely on an internal scoring strategy.`scoring` param.  \n",
    "3. Metric functions: The sklearn.metrics module implements functions assessing prediction error for specific purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb5356",
   "metadata": {},
   "source": [
    "### 3.4.6. Regression metrics\n",
    "\n",
    "The sklearn.metrics module implements several loss, score, and utility functions to **measure regression performance**. Some of those have been enhanced to handle the **multioutput** case (): mean_squared_error, mean_absolute_error, r2_score...\n",
    "\n",
    "These functions have a multioutput keyword argument:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb95fdd",
   "metadata": {},
   "source": [
    "#### 3.4.6.1. R² score, the coefficient of determination\n",
    "The r2_score function computes the coefficient of determination through the **proportion** of explained **variance**.\n",
    "$$R² = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a0e0a",
   "metadata": {},
   "source": [
    "$(-\\inf, 1]$\n",
    "- R^2 = 1 ：perfect\n",
    "-  R^2 = 0 ：imperfect, ability as the mean predict (all $\\hat{y}_i = \\bar{y}$)\n",
    "-  R^2 < 0 ：terrible\n",
    "\n",
    "$denominator=0$:\n",
    "- NaN -> 1.0\n",
    "- -inf -> 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3789acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9486081370449679"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "r2_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "553fb868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9253456221198156"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
    "y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
    "r2_score(y_true, y_pred, multioutput='variance_weighted')\n",
    "r2_score(y_true, y_pred, multioutput='uniform_average')\n",
    "r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "r2_score(y_true, y_pred, multioutput=[0.3, 0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae63ace",
   "metadata": {},
   "source": [
    "#### 3.4.6.2 others\n",
    "- Mean Absolute Error (MAE)\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "- Mean Squared Error (MSE)\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "- Median Absolute Error (MedAE)\n",
    "$$\n",
    "MedAE = \\text{median} \\left( \\left| y_i - \\hat{y}_i \\right| \\right)\n",
    "$$\n",
    "    - MedAE : outliers不敏感\n",
    "\n",
    "\n",
    "- Max Error\n",
    "$$\n",
    "Max Error = \\max \\left( \\left| y_i - \\hat{y}_i \\right| \\right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a5efaa",
   "metadata": {},
   "source": [
    "#### 3.4.6.12. Visual evaluation of regression models\n",
    "PredictionErrorDisplay class allows to visually inspect the prediction errors of a model in two different manners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d2c608",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
